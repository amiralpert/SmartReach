{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: GitHub Setup and Enhanced Import Configuration\n\n# Install required packages first\n!pip install edgartools transformers torch requests beautifulsoup4 'lxml[html_clean]' uuid numpy newspaper3k --quiet\n\nimport os\nimport sys\nimport importlib\nimport importlib.util\nimport psycopg2\nfrom edgar import set_identity\n\n# GitHub credentials - use Kaggle secrets for security\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ngithub_token = user_secrets.get_secret(\"GITHUB_TOKEN\")\nrepo_url = f\"https://{github_token}@github.com/amiralpert/SmartReach.git\"\nlocal_path = \"/kaggle/working/SmartReach\"\n\nprint(\"ğŸ“¦ Setting up GitHub repository...\")\n\n# Clone or update repo with force pull\nif os.path.exists(local_path):\n    print(f\"ğŸ“‚ Repository exists at {local_path}\")\n    print(\"ğŸ”„ Force updating from GitHub...\")\n    !cd {local_path} && git fetch origin\n    !cd {local_path} && git reset --hard origin/main\n    !cd {local_path} && git pull origin main\n    print(\"âœ… Repository updated\")\n    \n    # Show current commit\n    !cd {local_path} && echo \"Current commit:\" && git log --oneline -1\nelse:\n    print(f\"ğŸ“¥ Cloning repository to {local_path}\")\n    !git clone {repo_url} {local_path}\n    print(\"âœ… Repository cloned\")\n\n# Clear any cached modules from previous runs\nmodules_to_clear = [key for key in sys.modules.keys() if 'auto_logger' in key.lower() or 'clean' in key.lower()]\nfor mod in modules_to_clear:\n    del sys.modules[mod]\n    print(f\"  ğŸ§¹ Cleared cached module: {mod}\")\n\n# Add to Python path for regular imports\nif f'{local_path}/BizIntel' in sys.path:\n    sys.path.remove(f'{local_path}/BizIntel')\nsys.path.insert(0, f'{local_path}/BizIntel')\n\nprint(\"âœ“ Python path configured for SEC entity extraction!\")\n\n# Configure EdgarTools authentication - REQUIRED by SEC\nset_identity(\"SmartReach BizIntel amir@leanbio.consulting\")\nprint(\"ğŸ†” EdgarTools identity configured: SmartReach BizIntel amir@leanbio.consulting\")\n\n# Set up database configuration\nNEON_CONFIG = {\n    'host': 'ep-royal-star-ad1gn0d4-pooler.c-2.us-east-1.aws.neon.tech',\n    'database': 'BizIntelSmartReach',\n    'user': 'neondb_owner',\n    'password': 'npg_aTFt6Pug3Kpy',\n    'sslmode': 'require'\n}\n\n# Set up the new clean auto-logger\ntry:\n    # Create connection for logger\n    logger_conn = psycopg2.connect(**NEON_CONFIG)\n    print(\"âœ“ Database connected for clean logger\")\n\n    # Import the redesigned clean auto-logger\n    logger_module_path = f\"{local_path}/BizIntel/Scripts/KaggleLogger/auto_logger.py\"\n    if os.path.exists(logger_module_path):\n        spec = importlib.util.spec_from_file_location(\"auto_logger\", logger_module_path)\n        auto_logger_module = importlib.util.module_from_spec(spec)\n        sys.modules[\"auto_logger\"] = auto_logger_module\n        spec.loader.exec_module(auto_logger_module)\n\n        # Use the new clean logging setup\n        setup_clean_logging = auto_logger_module.setup_clean_logging\n        logger = setup_clean_logging(logger_conn, \"SEC_EntityExtraction\")\n        \n        print(\"âœ¨ Clean auto-logging enabled!\")\n        print(\"ğŸ“‹ Features:\")\n        print(\"   â€¢ One row per cell execution\")\n        print(\"   â€¢ Complete output capture\")\n        print(\"   â€¢ Proper cell numbers from # Cell N: comments\")\n        print(\"   â€¢ Full error tracebacks\")\n        print(\"   â€¢ Execution timing\")\n        \n    else:\n        print(f\"âœ— Clean auto-logger not found at {logger_module_path}\")\n        logger = None\n        \nexcept Exception as e:\n    print(f\"âš ï¸ Clean logger setup failed: {e}\")\n    print(\"  Continuing without auto-logging...\")\n    logger = None\n\nprint(\"\\nğŸš€ Setup complete! SEC Entity Extraction Engine with Enhanced EdgarTools Integration ready.\")\nprint(\"ğŸ’¡ Run cells with proper # Cell N: comments for best logging.\")\nprint(\"ğŸ”§ EdgarTools configured with section extraction capabilities.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Database Connection Test\n\nimport psycopg2\n\n# Test database connection\ndef test_database_connection():\n    try:\n        conn = psycopg2.connect(**NEON_CONFIG)\n        cursor = conn.cursor()\n        \n        # Check SEC-related tables\n        cursor.execute('''\n            SELECT \n                (SELECT COUNT(*) FROM raw_data.sec_filings) as sec_filings,\n                (SELECT COUNT(*) FROM core.companies) as companies,\n                (SELECT COUNT(*) FROM system_uno.sec_entities_raw) as sec_entities_extracted,\n                (SELECT COUNT(DISTINCT company_domain) FROM raw_data.sec_filings) as companies_with_filings,\n                (SELECT COUNT(*) FROM raw_data.sec_filings WHERE url IS NOT NULL) as filings_with_urls\n        ''')\n        \n        counts = cursor.fetchone()\n        print(\"âœ“ Database connected successfully!\")\n        print(f\"  SEC Filings: {counts[0]}\")\n        print(f\"  Companies: {counts[1]}\")\n        print(f\"  Extracted SEC Entities: {counts[2]}\")\n        print(f\"  Companies with SEC Filings: {counts[3]}\")\n        print(f\"  SEC Filings with URLs: {counts[4]}\")\n        \n        # Show sample SEC filing data\n        cursor.execute('''\n            SELECT company_domain, filing_type, COUNT(*) as count\n            FROM raw_data.sec_filings \n            GROUP BY company_domain, filing_type \n            ORDER BY company_domain, count DESC\n            LIMIT 10\n        ''')\n        \n        filing_stats = cursor.fetchall()\n        print(\"\\nğŸ“Š SEC Filing Distribution:\")\n        for stat in filing_stats:\n            print(f\"  {stat[0]}: {stat[1]} ({stat[2]} filings)\")\n        \n        cursor.close()\n        conn.close()\n        return True\n        \n    except Exception as e:\n        print(f\"âœ— Database connection failed: {e}\")\n        return False\n\n# Test connection\ntest_database_connection()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Accession-Based SEC Content Extraction with EdgarTools\n\nimport edgar\nfrom edgar import Filing, find, set_identity, Company\nfrom edgar.documents import parse_html\nfrom edgar.documents.extractors.section_extractor import SectionExtractor\nimport requests\nimport re\nfrom typing import Dict, List, Optional, Tuple\nfrom bs4 import BeautifulSoup\n\n# Ensure identity is set\nset_identity(\"SmartReach BizIntel amir@leanbio.consulting\")\n\ndef extract_accession_from_url(url: str) -> Optional[str]:\n    \"\"\"Extract accession number from SEC filing URL\"\"\"\n    # SEC filing URLs typically have format: \n    # https://www.sec.gov/Archives/edgar/data/CIK/ACCESSION_NUMBER/filename\n    \n    # Match standard pattern: 0001234567-23-000001\n    accession_match = re.search(r'(\\d{10}-\\d{2}-\\d{6})', url)\n    if accession_match:\n        return accession_match.group(1)\n    \n    # Match compressed pattern in URL path: 000123456723000001\n    compressed_match = re.search(r'/(\\d{18})/', url)\n    if compressed_match:\n        # Convert compressed format to standard format\n        accession = compressed_match.group(1)\n        return f\"{accession[:10]}-{accession[10:12]}-{accession[12:]}\"\n    \n    return None\n\ndef get_filing_sections(accession_number: str, filing_type: str = None) -> Dict[str, str]:\n    \"\"\"Get structured sections from SEC filing using accession number\"\"\"\n    try:\n        # Find filing using accession number\n        filing = find(accession_number)\n        \n        if not filing:\n            raise ValueError(f\"Filing not found for accession: {accession_number}\")\n        \n        # Auto-detect filing type if not provided\n        if not filing_type:\n            filing_type = getattr(filing, 'form', '10-K')\n        \n        print(f\"   ğŸ“„ Found {filing_type} for {getattr(filing, 'company', 'Unknown Company')}\")\n        \n        # Get structured HTML content\n        html_content = filing.html()\n        if not html_content:\n            raise ValueError(\"No HTML content available\")\n        \n        # Parse HTML to Document object\n        document = parse_html(html_content)\n        \n        # Extract sections using SectionExtractor\n        extractor = SectionExtractor(filing_type=filing_type)\n        sections = extractor.extract(document)\n        \n        print(f\"   ğŸ“‘ SectionExtractor found {len(sections)} sections: {list(sections.keys())}\")\n        \n        # Convert sections to text dictionary\n        section_texts = {}\n        for section_name, section in sections.items():\n            try:\n                if hasattr(section, 'text'):\n                    text = section.text() if callable(section.text) else section.text\n                    if isinstance(text, str) and text.strip():\n                        section_texts[section_name] = text.strip()\n                        print(f\"      â€¢ {section_name}: {len(text):,} chars\")\n                elif hasattr(section, '__str__'):\n                    text = str(section).strip()\n                    if text:\n                        section_texts[section_name] = text\n                        print(f\"      â€¢ {section_name}: {len(text):,} chars (via str)\")\n            except Exception as section_e:\n                print(f\"      âš ï¸ Could not extract {section_name}: {section_e}\")\n                continue\n        \n        # If SectionExtractor returns no sections, fall back to full document text\n        if not section_texts:\n            print(f\"   ğŸ”„ No structured sections found, using full document as 'full_document' section\")\n            full_text = document.text() if hasattr(document, 'text') and callable(document.text) else str(document)\n            if full_text and len(full_text.strip()) > 100:  # Only use if substantial content\n                section_texts['full_document'] = full_text.strip()\n                print(f\"      â€¢ full_document: {len(full_text):,} chars\")\n        \n        return section_texts\n        \n    except Exception as e:\n        print(f\"   âŒ Section extraction failed: {e}\")\n        return {}\n\ndef route_sections_to_models(sections: Dict[str, str], filing_type: str) -> Dict[str, List[str]]:\n    \"\"\"Route sections to appropriate NER models based on filing type\"\"\"\n    routing = {\n        'biobert': [],\n        'bert_base': [],\n        'roberta': [],\n        'finbert': []\n    }\n    \n    if filing_type.upper() in ['10-K', '10-Q']:\n        for section_name, section_text in sections.items():\n            # FinBERT gets financial statements exclusively\n            if 'financial' in section_name.lower() or 'statement' in section_name.lower():\n                routing['finbert'].append(section_name)\n            else:\n                # All other sections go to BERT/RoBERTa/BioBERT\n                routing['bert_base'].append(section_name)\n                routing['roberta'].append(section_name)\n                routing['biobert'].append(section_name)\n    \n    elif filing_type.upper() == '8-K':\n        # 8-K: all item sections go to all four models\n        for section_name in sections.keys():\n            routing['biobert'].append(section_name)\n            routing['bert_base'].append(section_name)\n            routing['roberta'].append(section_name)\n            routing['finbert'].append(section_name)\n    \n    else:\n        # Default routing for other filing types\n        for section_name in sections.keys():\n            routing['bert_base'].append(section_name)\n            routing['roberta'].append(section_name)\n            routing['biobert'].append(section_name)\n    \n    # Remove empty routing\n    routing = {model: sections_list for model, sections_list in routing.items() if sections_list}\n    \n    return routing\n\ndef process_sec_filing_with_sections(filing_data: Dict) -> Dict:\n    \"\"\"Process SEC filing with section-based extraction\"\"\"\n    try:\n        filing_id = filing_data.get('id')\n        filing_url = filing_data.get('url')\n        filing_type = filing_data.get('filing_type', '10-K')\n        company_domain = filing_data.get('company_domain', 'Unknown')\n        \n        print(f\"ğŸ¢ Processing {filing_type} for {company_domain}\")\n        print(f\"   ğŸ“„ Filing ID: {filing_id}\")\n        print(f\"   ğŸ”— URL: {filing_url}\")\n        \n        # Extract accession number\n        accession_number = extract_accession_from_url(filing_url)\n        if not accession_number:\n            raise ValueError(f\"Could not extract accession from URL: {filing_url}\")\n        \n        print(f\"   ğŸ“‹ Accession: {accession_number}\")\n        \n        # Get structured sections\n        sections = get_filing_sections(accession_number, filing_type)\n        if not sections:\n            raise ValueError(\"No sections extracted\")\n        \n        print(f\"   ğŸ“‘ Extracted {len(sections)} sections\")\n        \n        # Route sections to models\n        model_routing = route_sections_to_models(sections, filing_type)\n        print(f\"   ğŸ¯ Model routing: {[f'{model}: {len(secs)} sections' for model, secs in model_routing.items()]}\")\n        \n        return {\n            'filing_id': filing_id,\n            'company_domain': company_domain,\n            'filing_type': filing_type,\n            'accession_number': accession_number,\n            'url': filing_url,\n            'sections': sections,\n            'model_routing': model_routing,\n            'total_sections': len(sections),\n            'processing_status': 'success'\n        }\n        \n    except Exception as e:\n        print(f\"   âŒ Processing failed: {e}\")\n        return {\n            'filing_id': filing_data.get('id'),\n            'company_domain': filing_data.get('company_domain', 'Unknown'),\n            'filing_type': filing_data.get('filing_type', 'Unknown'),\n            'url': filing_data.get('url'),\n            'error': str(e),\n            'processing_status': 'failed'\n        }\n\ndef get_unprocessed_filings(limit: int = 5) -> List[Dict]:\n    \"\"\"Get SEC filings that haven't been processed yet\"\"\"\n    try:\n        conn = psycopg2.connect(**NEON_CONFIG)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n            SELECT sf.id, sf.company_domain, sf.filing_type, sf.url, sf.filing_date, sf.title\n            FROM raw_data.sec_filings sf\n            LEFT JOIN system_uno.sec_entities_raw ser ON ser.sec_filing_ref = CONCAT('SEC_', sf.id)\n            WHERE sf.url IS NOT NULL \n            AND ser.sec_filing_ref IS NULL\n            ORDER BY sf.filing_date DESC\n            LIMIT %s\n        \"\"\", (limit,))\n        \n        filings = cursor.fetchall()\n        cursor.close()\n        conn.close()\n        \n        return [{\n            'id': filing[0],\n            'company_domain': filing[1],\n            'filing_type': filing[2],\n            'url': filing[3],\n            'filing_date': filing[4],\n            'title': filing[5]\n        } for filing in filings]\n        \n    except Exception as e:\n        print(f\"âŒ Database query failed: {e}\")\n        return []\n\n# Test the accession-based extraction\nprint(\"ğŸ§ª Testing accession-based section extraction...\")\n\ntest_filings = get_unprocessed_filings(limit=1)\n\nif test_filings:\n    print(f\"ğŸ“„ Found {len(test_filings)} test filing(s)\")\n    \n    for filing in test_filings:\n        result = process_sec_filing_with_sections(filing)\n        \n        if result['processing_status'] == 'success':\n            print(f\"   âœ… Success: {result['total_sections']} sections extracted\")\n            print(f\"   ğŸ“Š Available sections: {list(result['sections'].keys())}\")\n            \n            # Show model routing summary\n            for model, section_list in result['model_routing'].items():\n                print(f\"   ğŸ¯ {model}: {len(section_list)} sections\")\n                \n            # Show sample section content\n            first_section = list(result['sections'].keys())[0]\n            sample_text = result['sections'][first_section][:200] + \"...\"\n            print(f\"   ğŸ“ Sample from '{first_section}': {sample_text}\")\n            \n        else:\n            print(f\"   âŒ Failed: {result.get('error', 'Unknown error')}\")\nelse:\n    print(\"ğŸ“­ No unprocessed filings found for testing\")\n\nprint(\"\\nâœ… Accession-based SEC section extraction ready!\")\nprint(\"ğŸ”§ Features:\")\nprint(\"   â€¢ Accession number extraction from URLs\")\nprint(\"   â€¢ EdgarTools section extraction with SectionExtractor\")\nprint(\"   â€¢ Fallback to full document if no sections found\")\nprint(\"   â€¢ Automatic model routing based on filing type\")\nprint(\"   â€¢ 10-K/10-Q: Financial sections â†’ FinBERT, Others â†’ BERT/RoBERTa/BioBERT\")\nprint(\"   â€¢ 8-K: All sections â†’ All models\")\nprint(\"   â€¢ Section-level content targeting for optimal entity extraction\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: EntityExtractionPipeline Class and NER Model Loading\n\nimport torch\nimport time\nimport uuid\nimport json\nfrom datetime import datetime\nfrom typing import List, Dict, Any, Optional\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\nfrom abc import ABC, abstractmethod\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nprint(\"ğŸš€ Loading EntityExtractionPipeline and NER Models...\")\n\nclass EntityExtractionPipeline:\n    \"\"\"Extensible pipeline for entity extraction from multiple data sources\"\"\"\n    \n    def __init__(self, db_config: Dict, model_config: Dict = None):\n        self.db_config = db_config\n        self.model_config = model_config or self._get_default_model_config()\n        self.loaded_models = {}\n        self.pipeline_stats = {\n            'documents_processed': 0,\n            'total_entities_extracted': 0,\n            'processing_time_total': 0,\n            'data_sources_supported': ['sec_filings', 'press_releases', 'patents']\n        }\n        \n        print(f\"ğŸ”§ EntityExtractionPipeline initialized\")\n        print(f\"   ğŸ“Š Supported data sources: {self.pipeline_stats['data_sources_supported']}\")\n    \n    def _get_default_model_config(self) -> Dict:\n        \"\"\"Default model configuration for biotech entity extraction\"\"\"\n        return {\n            'models': {\n                'biobert': {\n                    'model_name': 'alvaroalon2/biobert_diseases_ner',\n                    'confidence_threshold': 0.5,\n                    'description': 'Biomedical entities (diseases, medications, treatments)'\n                },\n                'bert_base': {\n                    'model_name': 'dslim/bert-base-NER',\n                    'confidence_threshold': 0.5,\n                    'description': 'General entities (persons, organizations, locations)'\n                },\n                'finbert': {\n                    'model_name': 'ProsusAI/finbert',\n                    'confidence_threshold': 0.5,\n                    'description': 'Financial entities and metrics'\n                },\n                'roberta': {\n                    'model_name': 'Jean-Baptiste/roberta-large-ner-english',\n                    'confidence_threshold': 0.6,\n                    'description': 'High-precision general entities'\n                }\n            },\n            'routing_rules': {\n                'sec_filings': {\n                    '10-K': {\n                        'financial_sections': ['finbert'],\n                        'other_sections': ['biobert', 'bert_base', 'roberta']\n                    },\n                    '10-Q': {\n                        'financial_sections': ['finbert'],\n                        'other_sections': ['biobert', 'bert_base', 'roberta']\n                    },\n                    '8-K': {\n                        'all_sections': ['biobert', 'bert_base', 'roberta', 'finbert']\n                    }\n                },\n                'press_releases': {\n                    'all_content': ['biobert', 'bert_base', 'roberta']\n                },\n                'patents': {\n                    'all_content': ['biobert', 'bert_base', 'roberta']\n                }\n            },\n            'entity_type_mapping': {\n                # BioBERT mappings\n                'Disease': 'MEDICAL_CONDITION',\n                'Chemical': 'MEDICATION',\n                'CHEMICAL': 'MEDICATION',\n                'DISEASE': 'MEDICAL_CONDITION',\n                'DRUG': 'MEDICATION',\n                'Drug': 'MEDICATION',\n                'Compound': 'MEDICATION',\n                'Treatment': 'THERAPY',\n                'Therapy': 'THERAPY',\n                \n                # BERT-base mappings\n                'PER': 'PERSON',\n                'ORG': 'ORGANIZATION',\n                'LOC': 'LOCATION',\n                'MISC': 'MISCELLANEOUS',\n                \n                # Financial mappings\n                'MONEY': 'FINANCIAL',\n                'PERCENT': 'FINANCIAL',\n                'NUMBER': 'METRIC'\n            }\n        }\n    \n    def load_models(self) -> Dict:\n        \"\"\"Load all NER models specified in configuration\"\"\"\n        print(f\"ğŸ“¦ Loading {len(self.model_config['models'])} NER models...\")\n        \n        for model_key, model_info in self.model_config['models'].items():\n            try:\n                model_name = model_info['model_name']\n                print(f\"   ğŸ§  Loading {model_key}: {model_name}\")\n                \n                tokenizer = AutoTokenizer.from_pretrained(model_name)\n                model = AutoModelForTokenClassification.from_pretrained(model_name)\n                ner_pipeline = pipeline(\n                    \"ner\", \n                    model=model, \n                    tokenizer=tokenizer,\n                    aggregation_strategy=\"average\", \n                    device=0 if torch.cuda.is_available() else -1\n                )\n                \n                self.loaded_models[model_key] = {\n                    'pipeline': ner_pipeline,\n                    'threshold': model_info['confidence_threshold'],\n                    'description': model_info['description'],\n                    'stats': {\n                        'texts_processed': 0,\n                        'entities_found': 0,\n                        'processing_time': 0\n                    }\n                }\n                \n                print(f\"      âœ“ {model_key} loaded (threshold: {model_info['confidence_threshold']})\")\n                \n            except Exception as e:\n                print(f\"      âŒ {model_key} failed: {e}\")\n                # Use BERT-base as fallback for failed models\n                if model_key != 'bert_base' and 'bert_base' in self.loaded_models:\n                    self.loaded_models[model_key] = self.loaded_models['bert_base']\n                    print(f\"      ğŸ”„ Using BERT-base fallback for {model_key}\")\n        \n        loaded_count = len(self.loaded_models)\n        device = \"GPU\" if torch.cuda.is_available() else \"CPU\"\n        \n        print(f\"   âœ… Successfully loaded: {loaded_count}/4 models on {device}\")\n        \n        return self.loaded_models\n    \n    def get_routing_for_content(self, data_source: str, filing_type: str = None, section_name: str = None) -> List[str]:\n        \"\"\"Get model routing for specific content\"\"\"\n        routing_rules = self.model_config['routing_rules']\n        \n        if data_source not in routing_rules:\n            # Default to all text models for unknown data sources\n            return ['biobert', 'bert_base', 'roberta']\n        \n        source_rules = routing_rules[data_source]\n        \n        if data_source == 'sec_filings' and filing_type:\n            filing_rules = source_rules.get(filing_type, source_rules.get('10-K'))\n            \n            # Check if it's a financial section\n            if section_name and any(fin_word in section_name.lower() \n                                  for fin_word in ['financial', 'statement', 'balance', 'income', 'cash']):\n                return filing_rules.get('financial_sections', ['finbert'])\n            else:\n                return filing_rules.get('other_sections', ['biobert', 'bert_base', 'roberta'])\n        \n        elif data_source in ['press_releases', 'patents']:\n            return source_rules['all_content']\n        \n        # Default routing\n        return ['biobert', 'bert_base', 'roberta']\n    \n    def extract_entities_from_text(self, text: str, model_name: str, metadata: Dict = None) -> List[Dict]:\n        \"\"\"Extract entities from text using specific model\"\"\"\n        if model_name not in self.loaded_models or not text.strip():\n            return []\n        \n        try:\n            start_time = time.time()\n            model_info = self.loaded_models[model_name]\n            \n            # Run NER pipeline\n            raw_entities = model_info['pipeline'](text)\n            \n            # Process and filter results\n            processed_entities = []\n            for entity in raw_entities:\n                if entity['score'] >= model_info['threshold']:\n                    # Normalize entity type\n                    entity_type = self.model_config['entity_type_mapping'].get(\n                        entity['entity_group'], entity['entity_group']\n                    )\n                    \n                    processed_entity = {\n                        'entity_text': entity['word'].strip(),\n                        'entity_type': entity_type,\n                        'confidence_score': float(entity['score']),\n                        'char_start': entity['start'],\n                        'char_end': entity['end'],\n                        'model_source': model_name,\n                        'original_label': entity['entity_group'],\n                        'extraction_id': str(uuid.uuid4()),\n                        'extraction_timestamp': datetime.now().isoformat()\n                    }\n                    \n                    # Add metadata if provided\n                    if metadata:\n                        processed_entity.update(metadata)\n                    \n                    processed_entities.append(processed_entity)\n            \n            # Update statistics\n            processing_time = time.time() - start_time\n            model_info['stats']['texts_processed'] += 1\n            model_info['stats']['entities_found'] += len(processed_entities)\n            model_info['stats']['processing_time'] += processing_time\n            \n            return processed_entities\n            \n        except Exception as e:\n            print(f\"   âŒ {model_name} extraction failed: {e}\")\n            return []\n    \n    def process_sec_filing_sections(self, filing_result: Dict) -> List[Dict]:\n        \"\"\"Process SEC filing sections with appropriate model routing\"\"\"\n        if filing_result.get('processing_status') != 'success':\n            return []\n        \n        filing_id = filing_result['filing_id']\n        filing_type = filing_result['filing_type']\n        company_domain = filing_result['company_domain']\n        sections = filing_result['sections']\n        \n        print(f\"ğŸ” Processing {len(sections)} sections for {company_domain} {filing_type}\")\n        \n        all_entities = []\n        \n        for section_name, section_text in sections.items():\n            # Get routing for this section\n            applicable_models = self.get_routing_for_content('sec_filings', filing_type, section_name)\n            applicable_models = [m for m in applicable_models if m in self.loaded_models]\n            \n            if not applicable_models:\n                continue\n            \n            print(f\"   ğŸ“‘ Processing '{section_name}' with {len(applicable_models)} models\")\n            \n            # Metadata for this section\n            section_metadata = {\n                'filing_id': filing_id,\n                'company_domain': company_domain,\n                'filing_type': filing_type,\n                'section_name': section_name,\n                'sec_filing_ref': f'SEC_{filing_id}',\n                'data_source': 'sec_filings'\n            }\n            \n            # Process with each applicable model\n            section_entities = []\n            for model_name in applicable_models:\n                model_entities = self.extract_entities_from_text(section_text, model_name, section_metadata)\n                section_entities.extend(model_entities)\n                print(f\"      â€¢ {model_name}: {len(model_entities)} entities\")\n            \n            all_entities.extend(section_entities)\n        \n        # Merge entities at same positions\n        merged_entities = self.merge_position_overlaps(all_entities)\n        print(f\"   ğŸ”— Merged: {len(all_entities)} â†’ {len(merged_entities)} entities\")\n        \n        return merged_entities\n    \n    def merge_position_overlaps(self, entities: List[Dict]) -> List[Dict]:\n        \"\"\"Merge entities detected at same position by different models\"\"\"\n        if not entities:\n            return []\n        \n        # Group entities by position\n        position_groups = {}\n        \n        for entity in entities:\n            # Create position key\n            pos_key = f\"{entity.get('filing_id', 'unknown')}_{entity.get('section_name', 'unknown')}_{entity.get('char_start', 0)}_{entity.get('char_end', 0)}\"\n            \n            if pos_key not in position_groups:\n                position_groups[pos_key] = []\n            position_groups[pos_key].append(entity)\n        \n        merged_entities = []\n        \n        for pos_key, group in position_groups.items():\n            if len(group) == 1:\n                merged_entities.append(group[0])\n            else:\n                # Merge multiple detections\n                merged = self._merge_entity_group(group)\n                merged_entities.append(merged)\n        \n        return merged_entities\n    \n    def _merge_entity_group(self, entities: List[Dict]) -> Dict:\n        \"\"\"Merge entities from different models at same position\"\"\"\n        # Priority for biotech domain: BioBERT > FinBERT > RoBERTa > BERT-base\n        priority = {'biobert': 4, 'finbert': 3, 'roberta': 2, 'bert_base': 1}\n        \n        # Sort by priority, then by confidence\n        entities.sort(key=lambda x: (priority.get(x['model_source'], 0), x['confidence_score']), reverse=True)\n        \n        # Use best entity as base\n        best = entities[0].copy()\n        \n        # Add multi-model metadata\n        best['models_detected'] = [e['model_source'] for e in entities]\n        best['all_confidences'] = {e['model_source']: e['confidence_score'] for e in entities}\n        best['primary_model'] = best['model_source']\n        best['entity_variations'] = {e['model_source']: e['entity_text'] for e in entities}\n        best['is_merged'] = True\n        best['confidence_score'] = max(e['confidence_score'] for e in entities)\n        \n        return best\n    \n    def add_data_source_support(self, source_name: str, routing_config: Dict, processor_func: callable = None):\n        \"\"\"Dynamically add support for new data sources\"\"\"\n        # Add to routing rules\n        self.model_config['routing_rules'][source_name] = routing_config\n        \n        # Add to supported sources\n        if source_name not in self.pipeline_stats['data_sources_supported']:\n            self.pipeline_stats['data_sources_supported'].append(source_name)\n        \n        print(f\"âœ… Added support for data source: {source_name}\")\n        print(f\"   ğŸ“Š Routing config: {routing_config}\")\n    \n    def get_pipeline_statistics(self) -> Dict:\n        \"\"\"Get comprehensive pipeline statistics\"\"\"\n        return {\n            'pipeline_stats': self.pipeline_stats.copy(),\n            'model_stats': {\n                name: info['stats'].copy() \n                for name, info in self.loaded_models.items()\n            },\n            'loaded_models': list(self.loaded_models.keys()),\n            'supported_data_sources': self.pipeline_stats['data_sources_supported'],\n            'device': \"GPU\" if torch.cuda.is_available() else \"CPU\"\n        }\n\n# Initialize the EntityExtractionPipeline\nentity_pipeline = EntityExtractionPipeline(NEON_CONFIG)\n\n# Load all NER models\nloaded_models = entity_pipeline.load_models()\n\n# Test the pipeline with sample text\nif loaded_models:\n    test_text = \"Pfizer's COVID-19 vaccine generated $37 billion in revenue. The FDA approved treatment for Alzheimer's disease in Boston.\"\n    print(f\"\\nğŸ§ª Testing models with sample text...\")\n    \n    for model_name, model_info in loaded_models.items():\n        try:\n            test_entities = entity_pipeline.extract_entities_from_text(test_text, model_name)\n            print(f\"   {model_name}: Found {len(test_entities)} entities\")\n            for entity in test_entities[:2]:\n                print(f\"      â€¢ {entity['entity_type']}: '{entity['entity_text']}' ({entity['confidence_score']:.3f})\")\n        except Exception as e:\n            print(f\"   {model_name}: Test failed - {e}\")\n\nprint(f\"\\nâœ… EntityExtractionPipeline ready!\")\nprint(f\"   ğŸ¯ Loaded models: {list(loaded_models.keys())}\")\nprint(f\"   ğŸ”§ Supported sources: {entity_pipeline.pipeline_stats['data_sources_supported']}\")\nprint(f\"   ğŸ’» Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\nprint(f\"   ğŸ“Š Ready for biotech-optimized entity extraction!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: GPU-Optimized Entity Storage and Database Integration\n\nimport psycopg2\nfrom psycopg2.extras import execute_values\nimport numpy as np\n\nclass PipelineEntityStorage:\n    \"\"\"Enhanced storage system for EntityExtractionPipeline results\"\"\"\n    \n    def __init__(self, db_config: Dict):\n        self.db_config = db_config\n        self.storage_stats = {\n            'total_entities_stored': 0,\n            'filings_processed': 0,\n            'merged_entities': 0,\n            'single_model_entities': 0,\n            'failed_inserts': 0\n        }\n        \n        # Ensure enhanced table structure\n        self._ensure_enhanced_table()\n    \n    def _ensure_enhanced_table(self):\n        \"\"\"Ensure table has all required columns for pipeline storage\"\"\"\n        try:\n            conn = psycopg2.connect(**self.db_config)\n            cursor = conn.cursor()\n            \n            # Check existing columns\n            cursor.execute(\"\"\"\n                SELECT column_name \n                FROM information_schema.columns \n                WHERE table_schema = 'system_uno' \n                AND table_name = 'sec_entities_raw'\n            \"\"\")\n            \n            existing_columns = {row[0] for row in cursor.fetchall()}\n            \n            # Required columns for pipeline\n            required_columns = {\n                'models_detected': 'TEXT[]',\n                'all_confidences': 'JSONB',\n                'primary_model': 'TEXT',\n                'entity_variations': 'JSONB',\n                'is_merged': 'BOOLEAN DEFAULT FALSE',\n                'section_name': 'TEXT',\n                'data_source': 'TEXT DEFAULT \\'sec_filings\\'',\n                'extraction_timestamp': 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP',\n                'original_label': 'TEXT'\n            }\n            \n            # Add missing columns\n            for col_name, col_type in required_columns.items():\n                if col_name not in existing_columns:\n                    cursor.execute(f'ALTER TABLE system_uno.sec_entities_raw ADD COLUMN {col_name} {col_type}')\n                    print(f\"   âœ“ Added column: {col_name}\")\n            \n            # Create indexes for performance\n            index_queries = [\n                'CREATE INDEX IF NOT EXISTS idx_sec_entities_pipeline_position ON system_uno.sec_entities_raw (sec_filing_ref, section_name, character_start, character_end)',\n                'CREATE INDEX IF NOT EXISTS idx_sec_entities_models ON system_uno.sec_entities_raw USING GIN (models_detected)',\n                'CREATE INDEX IF NOT EXISTS idx_sec_entities_source ON system_uno.sec_entities_raw (data_source, primary_model)',\n                'CREATE INDEX IF NOT EXISTS idx_sec_entities_merged ON system_uno.sec_entities_raw (is_merged, entity_category)'\n            ]\n            \n            for idx_query in index_queries:\n                cursor.execute(idx_query)\n            \n            conn.commit()\n            cursor.close()\n            conn.close()\n            print(\"âœ“ Enhanced table structure verified\")\n            \n        except Exception as e:\n            print(f\"âš ï¸ Table enhancement failed: {e}\")\n    \n    def store_pipeline_entities(self, entities: List[Dict]) -> bool:\n        \"\"\"Store entities from EntityExtractionPipeline\"\"\"\n        if not entities:\n            return True\n        \n        try:\n            conn = psycopg2.connect(**self.db_config)\n            cursor = conn.cursor()\n            \n            print(f\"ğŸ’¾ Storing {len(entities)} pipeline entities...\")\n            \n            # Debug: check section names in entities\n            section_names = [e.get('section_name', 'MISSING') for e in entities]\n            unique_sections = set(section_names)\n            print(f\"   ğŸ” Section names in entities: {unique_sections}\")\n            \n            # Prepare batch insert data\n            insert_data = []\n            merged_count = 0\n            \n            for entity in entities:\n                # Convert entity data for database\n                models_detected = entity.get('models_detected', [entity.get('model_source', 'unknown')])\n                if not isinstance(models_detected, list):\n                    models_detected = [str(models_detected)]\n                \n                all_confidences = entity.get('all_confidences', {entity.get('model_source', 'unknown'): entity.get('confidence_score', 0.0)})\n                entity_variations = entity.get('entity_variations', {entity.get('model_source', 'unknown'): entity.get('entity_text', '')})\n                \n                is_merged = entity.get('is_merged', False)\n                if is_merged:\n                    merged_count += 1\n                \n                # Ensure section_name is properly captured\n                section_name = entity.get('section_name', '')\n                if not section_name:\n                    # Debug missing section name\n                    print(f\"   âš ï¸ Missing section name for entity: {entity.get('entity_text', 'unknown')[:30]}...\")\n                \n                insert_tuple = (\n                    entity.get('extraction_id', str(uuid.uuid4())),\n                    entity.get('company_domain', ''),\n                    entity.get('entity_text', '').strip()[:1000],\n                    entity.get('entity_type', 'UNKNOWN'),\n                    float(entity.get('confidence_score', 0.0)),\n                    int(entity.get('char_start', 0)),\n                    int(entity.get('char_end', 0)),\n                    entity.get('surrounding_text', '')[:2000] if entity.get('surrounding_text') else '',\n                    entity.get('sec_filing_ref', ''),\n                    models_detected,\n                    json.dumps(all_confidences),\n                    entity.get('primary_model', entity.get('model_source', 'unknown')),\n                    json.dumps(entity_variations),\n                    is_merged,\n                    section_name,  # Store section name properly\n                    entity.get('data_source', 'sec_filings'),\n                    entity.get('extraction_timestamp'),\n                    entity.get('original_label', '')\n                )\n                \n                insert_data.append(insert_tuple)\n            \n            # Batch insert with enhanced schema\n            insert_query = \"\"\"\n                INSERT INTO system_uno.sec_entities_raw \n                (extraction_id, company_domain, entity_text, entity_category, \n                 confidence_score, character_start, character_end, surrounding_text, \n                 sec_filing_ref, models_detected, all_confidences, primary_model,\n                 entity_variations, is_merged, section_name, data_source,\n                 extraction_timestamp, original_label)\n                VALUES %s\n                ON CONFLICT (extraction_id) DO UPDATE SET\n                    models_detected = EXCLUDED.models_detected,\n                    all_confidences = EXCLUDED.all_confidences,\n                    primary_model = EXCLUDED.primary_model,\n                    entity_variations = EXCLUDED.entity_variations,\n                    is_merged = EXCLUDED.is_merged,\n                    section_name = EXCLUDED.section_name\n            \"\"\"\n            \n            execute_values(cursor, insert_query, insert_data, page_size=100)\n            rows_affected = cursor.rowcount\n            \n            conn.commit()\n            cursor.close()\n            conn.close()\n            \n            # Update statistics\n            self.storage_stats['total_entities_stored'] += len(entities)\n            self.storage_stats['merged_entities'] += merged_count\n            self.storage_stats['single_model_entities'] += len(entities) - merged_count\n            \n            print(f\"   âœ… Stored {rows_affected} entities\")\n            print(f\"   ğŸ”— Merged: {merged_count}, Single-model: {len(entities) - merged_count}\")\n            print(f\"   ğŸ“‘ Sections represented: {len(unique_sections)} unique section names\")\n            \n            return True\n            \n        except Exception as e:\n            print(f\"   âŒ Storage failed: {e}\")\n            self.storage_stats['failed_inserts'] += len(entities)\n            return False\n    \n    def get_storage_verification(self, sec_filing_ref: str) -> Dict:\n        \"\"\"Verify stored entities for a specific filing\"\"\"\n        try:\n            conn = psycopg2.connect(**self.db_config)\n            cursor = conn.cursor()\n            \n            # Enhanced verification with pipeline-specific fields\n            cursor.execute(\"\"\"\n                SELECT \n                    entity_category,\n                    COUNT(*) as total_count,\n                    AVG(confidence_score) as avg_confidence,\n                    COUNT(*) FILTER (WHERE is_merged = true) as merged_count,\n                    COUNT(DISTINCT primary_model) as models_used,\n                    COUNT(DISTINCT section_name) as sections_processed,\n                    MAX(extraction_timestamp) as latest_extraction\n                FROM system_uno.sec_entities_raw\n                WHERE sec_filing_ref = %s\n                GROUP BY entity_category\n                ORDER BY total_count DESC\n            \"\"\", (sec_filing_ref,))\n            \n            category_stats = cursor.fetchall()\n            \n            # Model performance breakdown\n            cursor.execute(\"\"\"\n                SELECT \n                    primary_model,\n                    COUNT(*) as entities,\n                    AVG(confidence_score) as avg_conf,\n                    COUNT(DISTINCT section_name) as sections\n                FROM system_uno.sec_entities_raw\n                WHERE sec_filing_ref = %s\n                GROUP BY primary_model\n                ORDER BY entities DESC\n            \"\"\", (sec_filing_ref,))\n            \n            model_stats = cursor.fetchall()\n            \n            cursor.close()\n            conn.close()\n            \n            return {\n                'filing_ref': sec_filing_ref,\n                'total_entities': sum(stat[1] for stat in category_stats),\n                'categories': [{\n                    'category': stat[0],\n                    'count': stat[1],\n                    'avg_confidence': float(stat[2]),\n                    'merged_count': stat[3],\n                    'models_used': stat[4],\n                    'sections_processed': stat[5]\n                } for stat in category_stats],\n                'model_performance': [{\n                    'model': stat[0],\n                    'entities': stat[1],\n                    'avg_confidence': float(stat[2]),\n                    'sections': stat[3]\n                } for stat in model_stats]\n            }\n            \n        except Exception as e:\n            print(f\"âŒ Verification failed: {e}\")\n            return {}\n\n# Initialize enhanced storage\npipeline_storage = PipelineEntityStorage(NEON_CONFIG)\n\n# Complete pipeline processing function\ndef process_filing_with_pipeline(filing_data: Dict) -> Dict:\n    \"\"\"Process single filing through complete pipeline\"\"\"\n    try:\n        start_time = time.time()\n        \n        # Step 1: Extract sections using accession-based method\n        section_result = process_sec_filing_with_sections(filing_data)\n        \n        if section_result['processing_status'] != 'success':\n            return {\n                'success': False,\n                'filing_id': filing_data.get('id'),\n                'error': section_result.get('error', 'Section extraction failed'),\n                'processing_time': time.time() - start_time\n            }\n        \n        # Step 2: Process sections through EntityExtractionPipeline\n        entities = entity_pipeline.process_sec_filing_sections(section_result)\n        \n        if not entities:\n            return {\n                'success': False,\n                'filing_id': filing_data.get('id'),\n                'error': 'No entities extracted',\n                'processing_time': time.time() - start_time\n            }\n        \n        # Step 3: Store entities\n        storage_success = pipeline_storage.store_pipeline_entities(entities)\n        \n        # Step 4: Get verification\n        verification = pipeline_storage.get_storage_verification(f\"SEC_{filing_data.get('id')}\")\n        \n        processing_time = time.time() - start_time\n        \n        result = {\n            'success': storage_success,\n            'filing_id': filing_data.get('id'),\n            'company_domain': filing_data.get('company_domain'),\n            'filing_type': filing_data.get('filing_type'),\n            'sections_processed': section_result.get('total_sections', 0),\n            'entities_extracted': len(entities),\n            'entities_stored': verification.get('total_entities', 0),\n            'processing_time': round(processing_time, 2),\n            'verification': verification,\n            'sample_entities': entities[:3]  # First 3 entities as sample\n        }\n        \n        return result\n        \n    except Exception as e:\n        return {\n            'success': False,\n            'filing_id': filing_data.get('id'),\n            'error': str(e),\n            'processing_time': time.time() - start_time\n        }\n\ndef process_filings_batch(limit: int = 3) -> Dict:\n    \"\"\"Process multiple filings in batch\"\"\"\n    print(f\"ğŸš€ Processing batch of {limit} SEC filings with complete pipeline...\")\n    \n    batch_start = time.time()\n    \n    # Get unprocessed filings\n    filings = get_unprocessed_filings(limit)\n    \n    if not filings:\n        return {'success': False, 'message': 'No filings to process'}\n    \n    print(f\"ğŸ“„ Found {len(filings)} filings to process\")\n    \n    # Process each filing\n    results = []\n    successful = 0\n    total_entities = 0\n    \n    for i, filing in enumerate(filings, 1):\n        print(f\"\\nğŸ“„ [{i}/{len(filings)}] Processing {filing['filing_type']} for {filing['company_domain']}\")\n        \n        result = process_filing_with_pipeline(filing)\n        results.append(result)\n        \n        if result['success']:\n            successful += 1\n            total_entities += result.get('entities_extracted', 0)\n            print(f\"   âœ… Success: {result['entities_extracted']} entities extracted in {result['processing_time']}s\")\n            \n            # Show sample entities with section names\n            for entity in result.get('sample_entities', []):\n                models = '+'.join(entity.get('models_detected', [entity.get('model_source', 'unknown')]))\n                section = entity.get('section_name', 'NO_SECTION')\n                print(f\"      â€¢ {entity['entity_type']}: '{entity['entity_text']}' ({models}, {entity['confidence_score']:.3f}, {section})\")\n        else:\n            print(f\"   âŒ Failed: {result.get('error', 'Unknown error')}\")\n        \n        # Brief pause between filings\n        if i < len(filings):\n            time.sleep(1)\n    \n    batch_time = time.time() - batch_start\n    \n    # Update pipeline statistics\n    entity_pipeline.pipeline_stats['documents_processed'] += successful\n    entity_pipeline.pipeline_stats['total_entities_extracted'] += total_entities\n    entity_pipeline.pipeline_stats['processing_time_total'] += batch_time\n    \n    # Update storage statistics\n    pipeline_storage.storage_stats['filings_processed'] += successful\n    \n    batch_summary = {\n        'success': successful > 0,\n        'filings_processed': len(filings),\n        'successful_filings': successful,\n        'failed_filings': len(filings) - successful,\n        'total_entities_extracted': total_entities,\n        'batch_processing_time': round(batch_time, 2),\n        'avg_time_per_filing': round(batch_time / len(filings), 2),\n        'results': results\n    }\n    \n    return batch_summary\n\n# Test the complete pipeline\nprint(\"ğŸ§ª Testing complete pipeline with sample filing...\")\n\ntest_filings = get_unprocessed_filings(limit=1)\n\nif test_filings:\n    test_result = process_filing_with_pipeline(test_filings[0])\n    \n    if test_result['success']:\n        print(f\"âœ… Pipeline test successful!\")\n        print(f\"   ğŸ“Š Sections processed: {test_result['sections_processed']}\")\n        print(f\"   ğŸ” Entities extracted: {test_result['entities_extracted']}\")\n        print(f\"   ğŸ’¾ Entities stored: {test_result['entities_stored']}\")\n        print(f\"   â±ï¸ Processing time: {test_result['processing_time']}s\")\n        \n        # Show verification details\n        if test_result['verification']:\n            print(f\"   ğŸ“ˆ Verification:\")\n            for cat in test_result['verification']['categories'][:3]:\n                print(f\"      â€¢ {cat['category']}: {cat['count']} entities\")\n    else:\n        print(f\"âŒ Pipeline test failed: {test_result.get('error')}\")\nelse:\n    print(\"ğŸ“­ No test filings available\")\n\nprint(f\"\\nâœ… Complete EntityExtractionPipeline with enhanced storage ready!\")\nprint(f\"ğŸ¯ Usage: batch_results = process_filings_batch(limit=5)\")\nprint(f\"ğŸ“Š Features: Section extraction â†’ NER processing â†’ Database storage\")\nprint(f\"ğŸ”§ Enhanced: Multi-model merging, performance tracking, detailed verification\")\nprint(f\"ğŸ·ï¸ Fixed: Section name attribution and storage verification\")\n\n# Context Retrieval System for Relationship Extraction\nclass ContextRetrievalSystem:\n    \"\"\"System to retrieve context around entities for relationship extraction\"\"\"\n    \n    def __init__(self, db_config: Dict):\n        self.db_config = db_config\n        self.retrieval_stats = {\n            'contexts_retrieved': 0,\n            'section_fetches': 0,\n            'failed_retrievals': 0,\n            'cache_hits': 0\n        }\n        # Simple cache for section content to avoid repeated API calls\n        self._section_cache = {}\n    \n    def get_entity_context(self, entity_id: str, context_window: int = 500) -> Dict:\n        \"\"\"Get context around a specific entity using its position and section\"\"\"\n        try:\n            conn = psycopg2.connect(**self.db_config)\n            cursor = conn.cursor()\n            \n            # Get entity details with section and position\n            cursor.execute(\"\"\"\n                SELECT \n                    entity_text, section_name, character_start, character_end,\n                    sec_filing_ref, company_domain, entity_category,\n                    confidence_score, primary_model\n                FROM system_uno.sec_entities_raw\n                WHERE extraction_id = %s\n                  AND section_name IS NOT NULL \n                  AND section_name != ''\n            \"\"\", (entity_id,))\n            \n            entity_data = cursor.fetchone()\n            cursor.close()\n            conn.close()\n            \n            if not entity_data:\n                return {\n                    'success': False, \n                    'error': 'Entity not found or missing section name',\n                    'entity_id': entity_id\n                }\n            \n            entity_text, section_name, char_start, char_end, sec_filing_ref, company_domain, category, confidence, model = entity_data\n            \n            # Extract filing ID from reference\n            filing_id = sec_filing_ref.replace('SEC_', '') if sec_filing_ref else None\n            if not filing_id:\n                return {\n                    'success': False,\n                    'error': 'Could not extract filing ID',\n                    'entity_id': entity_id\n                }\n            \n            # Get filing URL to extract accession\n            conn = psycopg2.connect(**self.db_config)\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"\n                SELECT url, filing_type, title\n                FROM raw_data.sec_filings\n                WHERE id = %s\n            \"\"\", (filing_id,))\n            \n            filing_info = cursor.fetchone()\n            cursor.close()\n            conn.close()\n            \n            if not filing_info:\n                return {\n                    'success': False,\n                    'error': f'Filing {filing_id} not found',\n                    'entity_id': entity_id\n                }\n            \n            filing_url, filing_type, filing_title = filing_info\n            \n            # Get section content\n            section_content = self._get_section_content(filing_url, filing_type, section_name)\n            \n            if not section_content:\n                return {\n                    'success': False,\n                    'error': f'Could not retrieve section {section_name}',\n                    'entity_id': entity_id\n                }\n            \n            # Extract context around entity position\n            context_start = max(0, char_start - context_window)\n            context_end = min(len(section_content), char_end + context_window)\n            \n            context_text = section_content[context_start:context_end]\n            \n            # Find entity position within context\n            entity_pos_in_context = char_start - context_start\n            \n            self.retrieval_stats['contexts_retrieved'] += 1\n            \n            return {\n                'success': True,\n                'entity_id': entity_id,\n                'entity_text': entity_text,\n                'entity_category': category,\n                'context_text': context_text,\n                'entity_position_in_context': entity_pos_in_context,\n                'entity_length': char_end - char_start,\n                'context_window_used': context_window,\n                'section_name': section_name,\n                'filing_info': {\n                    'filing_id': filing_id,\n                    'company_domain': company_domain,\n                    'filing_type': filing_type,\n                    'filing_title': filing_title\n                },\n                'metadata': {\n                    'confidence_score': confidence,\n                    'primary_model': model,\n                    'original_char_start': char_start,\n                    'original_char_end': char_end,\n                    'section_length': len(section_content)\n                }\n            }\n            \n        except Exception as e:\n            self.retrieval_stats['failed_retrievals'] += 1\n            return {\n                'success': False,\n                'error': str(e),\n                'entity_id': entity_id\n            }\n    \n    def _get_section_content(self, filing_url: str, filing_type: str, section_name: str) -> str:\n        \"\"\"Get section content using EdgarTools, with caching\"\"\"\n        cache_key = f\"{filing_url}#{section_name}\"\n        \n        # Check cache first\n        if cache_key in self._section_cache:\n            self.retrieval_stats['cache_hits'] += 1\n            return self._section_cache[cache_key]\n        \n        try:\n            from edgar import find\n            from edgar.documents import parse_html\n            from edgar.documents.extractors.section_extractor import SectionExtractor\n            import re\n            \n            # Extract accession from URL\n            accession_match = re.search(r'(\\d{10}-\\d{2}-\\d{6})', filing_url)\n            if not accession_match:\n                compressed_match = re.search(r'/(\\d{18})/', filing_url)\n                if compressed_match:\n                    accession = compressed_match.group(1)\n                    accession_number = f\"{accession[:10]}-{accession[10:12]}-{accession[12:]}\"\n                else:\n                    return None\n            else:\n                accession_number = accession_match.group(1)\n            \n            # Get filing and extract sections\n            filing = find(accession_number)\n            if not filing:\n                return None\n            \n            html_content = filing.html()\n            if not html_content:\n                return None\n            \n            document = parse_html(html_content)\n            extractor = SectionExtractor(filing_type=filing_type)\n            sections = extractor.extract(document)\n            \n            self.retrieval_stats['section_fetches'] += 1\n            \n            # Find the specific section\n            if section_name in sections:\n                section_obj = sections[section_name]\n                if hasattr(section_obj, 'text'):\n                    content = section_obj.text() if callable(section_obj.text) else section_obj.text\n                else:\n                    content = str(section_obj)\n                \n                # Cache the result\n                self._section_cache[cache_key] = content\n                return content\n            \n            return None\n            \n        except Exception as e:\n            print(f\"âš ï¸ Section retrieval failed for {section_name}: {e}\")\n            return None\n    \n    def get_co_occurring_entities(self, filing_id: str, section_name: str, distance_threshold: int = 1000) -> List[Dict]:\n        \"\"\"Get entities that co-occur within a distance threshold in the same section\"\"\"\n        try:\n            conn = psycopg2.connect(**self.db_config)\n            cursor = conn.cursor()\n            \n            # Get all entities in the same section\n            cursor.execute(\"\"\"\n                SELECT \n                    extraction_id, entity_text, entity_category, character_start, character_end,\n                    confidence_score, primary_model\n                FROM system_uno.sec_entities_raw\n                WHERE sec_filing_ref = %s\n                  AND section_name = %s\n                  AND section_name IS NOT NULL\n                ORDER BY character_start\n            \"\"\", (f'SEC_{filing_id}', section_name))\n            \n            entities = cursor.fetchall()\n            cursor.close()\n            conn.close()\n            \n            if len(entities) < 2:\n                return []\n            \n            # Find co-occurring pairs\n            co_occurrences = []\n            \n            for i in range(len(entities)):\n                for j in range(i + 1, len(entities)):\n                    entity1 = entities[i]\n                    entity2 = entities[j]\n                    \n                    # Calculate distance between entities\n                    distance = entity2[3] - entity1[4]  # start of entity2 - end of entity1\n                    \n                    if 0 <= distance <= distance_threshold:\n                        co_occurrences.append({\n                            'entity1': {\n                                'id': entity1[0],\n                                'text': entity1[1],\n                                'category': entity1[2],\n                                'start': entity1[3],\n                                'end': entity1[4],\n                                'confidence': entity1[5],\n                                'model': entity1[6]\n                            },\n                            'entity2': {\n                                'id': entity2[0],\n                                'text': entity2[1],\n                                'category': entity2[2],\n                                'start': entity2[3],\n                                'end': entity2[4],\n                                'confidence': entity2[5],\n                                'model': entity2[6]\n                            },\n                            'distance': distance,\n                            'section_name': section_name,\n                            'filing_id': filing_id\n                        })\n            \n            return co_occurrences\n            \n        except Exception as e:\n            print(f\"âŒ Co-occurrence search failed: {e}\")\n            return []\n    \n    def get_context_for_entity_pair(self, entity1_id: str, entity2_id: str, context_window: int = 300) -> Dict:\n        \"\"\"Get shared context for a pair of entities\"\"\"\n        try:\n            # Get context for both entities\n            context1 = self.get_entity_context(entity1_id, context_window)\n            context2 = self.get_entity_context(entity2_id, context_window)\n            \n            if not (context1['success'] and context2['success']):\n                return {\n                    'success': False,\n                    'error': 'Could not retrieve context for one or both entities'\n                }\n            \n            # Verify they're from same section\n            if context1['section_name'] != context2['section_name']:\n                return {\n                    'success': False,\n                    'error': 'Entities are not in the same section'\n                }\n            \n            # Find overlapping context or create combined context\n            entity1_start = context1['metadata']['original_char_start']\n            entity1_end = context1['metadata']['original_char_end']\n            entity2_start = context2['metadata']['original_char_start']\n            entity2_end = context2['metadata']['original_char_end']\n            \n            # Calculate combined context boundaries\n            combined_start = min(entity1_start, entity2_start) - context_window\n            combined_end = max(entity1_end, entity2_end) + context_window\n            \n            # Get section content and extract combined context\n            filing_url_query = f\"\"\"\n                SELECT url, filing_type, title \n                FROM raw_data.sec_filings \n                WHERE id = %s\n            \"\"\"\n            \n            conn = psycopg2.connect(**self.db_config)\n            cursor = conn.cursor()\n            cursor.execute(filing_url_query, (context1['filing_info']['filing_id'],))\n            filing_info = cursor.fetchone()\n            cursor.close()\n            conn.close()\n            \n            if not filing_info:\n                return {'success': False, 'error': 'Filing not found'}\n            \n            section_content = self._get_section_content(\n                filing_info[0], filing_info[1], context1['section_name']\n            )\n            \n            if not section_content:\n                return {'success': False, 'error': 'Section content not found'}\n            \n            # Extract combined context\n            combined_start = max(0, combined_start)\n            combined_end = min(len(section_content), combined_end)\n            combined_context = section_content[combined_start:combined_end]\n            \n            # Calculate relative positions within combined context\n            entity1_rel_start = entity1_start - combined_start\n            entity1_rel_end = entity1_end - combined_start\n            entity2_rel_start = entity2_start - combined_start\n            entity2_rel_end = entity2_end - combined_start\n            \n            return {\n                'success': True,\n                'entity1': context1['entity_text'],\n                'entity2': context2['entity_text'],\n                'combined_context': combined_context,\n                'entity1_position': {'start': entity1_rel_start, 'end': entity1_rel_end},\n                'entity2_position': {'start': entity2_rel_start, 'end': entity2_rel_end},\n                'distance_between_entities': abs(entity1_start - entity2_start),\n                'section_name': context1['section_name'],\n                'filing_info': context1['filing_info']\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e)\n            }\n    \n    def get_retrieval_statistics(self) -> Dict:\n        \"\"\"Get context retrieval system statistics\"\"\"\n        cache_size = len(self._section_cache)\n        return {\n            **self.retrieval_stats,\n            'cache_size': cache_size,\n            'cache_hit_rate': self.retrieval_stats['cache_hits'] / max(1, self.retrieval_stats['section_fetches']) * 100\n        }\n\n# Initialize context retrieval system\ncontext_retriever = ContextRetrievalSystem(NEON_CONFIG)\n\nprint(f\"\\nğŸ” ContextRetrievalSystem initialized!\")\nprint(f\"   ğŸ“Š Features: Entity context extraction, co-occurrence detection\")\nprint(f\"   ğŸ”§ Methods: get_entity_context(), get_co_occurring_entities(), get_context_for_entity_pair()\")\nprint(f\"   ğŸ’¾ Caching: Automatic section content caching to reduce API calls\")\nprint(f\"   ğŸ“ˆ Ready for relationship extraction preparation!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Production Analytics and Monitoring Interface\n\ndef generate_pipeline_analytics_report() -> None:\n    \"\"\"Generate comprehensive analytics report for the pipeline\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"ğŸ“Š ENTITYEXTRACTIONPIPELINE ANALYTICS DASHBOARD\")\n    print(\"=\"*80)\n    \n    # Database overview with enhanced metrics\n    try:\n        conn = psycopg2.connect(**NEON_CONFIG)\n        cursor = conn.cursor()\n        \n        # Enhanced database statistics\n        cursor.execute(\"\"\"\n            SELECT \n                COUNT(*) as total_entities,\n                COUNT(DISTINCT company_domain) as companies,\n                COUNT(DISTINCT sec_filing_ref) as filings,\n                COUNT(DISTINCT entity_category) as entity_types,\n                AVG(confidence_score) as avg_confidence,\n                COUNT(*) FILTER (WHERE is_merged = true) as merged_entities,\n                COUNT(DISTINCT primary_model) as active_models,\n                COUNT(DISTINCT section_name) as sections_processed,\n                MAX(extraction_timestamp) as last_extraction\n            FROM system_uno.sec_entities_raw\n            WHERE data_source = 'sec_filings'\n        \"\"\")\n        \n        db_overview = cursor.fetchone()\n        \n        # Model performance comparison\n        cursor.execute(\"\"\"\n            SELECT \n                primary_model,\n                COUNT(*) as entity_count,\n                AVG(confidence_score) as avg_confidence,\n                COUNT(DISTINCT entity_category) as categories_found,\n                COUNT(DISTINCT sec_filing_ref) as filings_processed,\n                COUNT(*) FILTER (WHERE is_merged = true) as merged_contributions\n            FROM system_uno.sec_entities_raw\n            WHERE primary_model IS NOT NULL\n            GROUP BY primary_model\n            ORDER BY entity_count DESC\n        \"\"\")\n        \n        model_performance = cursor.fetchall()\n        \n        # Entity category insights\n        cursor.execute(\"\"\"\n            SELECT \n                entity_category,\n                COUNT(*) as total_count,\n                AVG(confidence_score) as avg_confidence,\n                COUNT(DISTINCT primary_model) as models_detecting,\n                COUNT(*) FILTER (WHERE is_merged = true) as multi_model_detections,\n                COUNT(DISTINCT company_domain) as companies_with_category\n            FROM system_uno.sec_entities_raw\n            GROUP BY entity_category\n            HAVING COUNT(*) >= 5\n            ORDER BY total_count DESC\n            LIMIT 15\n        \"\"\")\n        \n        category_insights = cursor.fetchall()\n        \n        # Section-level analysis\n        cursor.execute(\"\"\"\n            SELECT \n                section_name,\n                COUNT(*) as entities_found,\n                COUNT(DISTINCT entity_category) as categories,\n                AVG(confidence_score) as avg_confidence,\n                COUNT(DISTINCT primary_model) as models_used\n            FROM system_uno.sec_entities_raw\n            WHERE section_name IS NOT NULL AND section_name != ''\n            GROUP BY section_name\n            HAVING COUNT(*) >= 3\n            ORDER BY entities_found DESC\n            LIMIT 10\n        \"\"\")\n        \n        section_analysis = cursor.fetchall()\n        \n        # Multi-model collaboration stats\n        cursor.execute(\"\"\"\n            SELECT \n                array_length(models_detected, 1) as num_models,\n                COUNT(*) as entity_count,\n                AVG(confidence_score) as avg_confidence\n            FROM system_uno.sec_entities_raw\n            WHERE models_detected IS NOT NULL\n            GROUP BY array_length(models_detected, 1)\n            ORDER BY num_models\n        \"\"\")\n        \n        collaboration_stats = cursor.fetchall()\n        \n        cursor.close()\n        conn.close()\n        \n        # Display results\n        if db_overview and db_overview[0]:\n            print(f\"\\nğŸ“ˆ DATABASE OVERVIEW:\")\n            print(f\"   Total Entities Extracted: {db_overview[0]:,}\")\n            print(f\"   Companies Processed: {db_overview[1]:,}\")\n            print(f\"   SEC Filings Analyzed: {db_overview[2]:,}\")\n            print(f\"   Entity Categories Found: {db_overview[3]:,}\")\n            print(f\"   Average Confidence Score: {db_overview[4]:.3f}\")\n            print(f\"   Multi-Model Entities: {db_overview[5]:,} ({db_overview[5]/db_overview[0]*100:.1f}%)\")\n            print(f\"   Active Models: {db_overview[6]:,}\")\n            print(f\"   Sections Processed: {db_overview[7]:,}\")\n            print(f\"   Last Extraction: {db_overview[8] or 'Never'}\")\n        \n        if model_performance:\n            print(f\"\\nğŸ¤– MODEL PERFORMANCE COMPARISON:\")\n            for model_data in model_performance:\n                model, count, conf, categories, filings, merged = model_data\n                merged_pct = (merged / count * 100) if count > 0 else 0\n                print(f\"   {model:>12}: {count:>6,} entities | {conf:.3f} conf | {categories:>2} categories | {filings:>3} filings | {merged_pct:>4.1f}% merged\")\n        \n        if category_insights:\n            print(f\"\\nğŸ·ï¸ ENTITY CATEGORY INSIGHTS:\")\n            print(f\"   {'Category':<20} {'Count':<8} {'Avg Conf':<10} {'Models':<7} {'Multi-Model':<12} {'Companies':<10}\")\n            print(f\"   {'-'*20} {'-'*8} {'-'*10} {'-'*7} {'-'*12} {'-'*10}\")\n            for cat_data in category_insights:\n                cat, count, conf, models, merged, companies = cat_data\n                merged_pct = (merged / count * 100) if count > 0 else 0\n                print(f\"   {cat:<20} {count:<8,} {conf:<10.3f} {models:<7} {merged_pct:<12.1f}% {companies:<10}\")\n        \n        if section_analysis:\n            print(f\"\\nğŸ“‘ SECTION-LEVEL PERFORMANCE:\")\n            for section_data in section_analysis:\n                section, entities, categories, conf, models = section_data\n                print(f\"   {section:<25}: {entities:>4} entities | {categories:>2} categories | {conf:.3f} conf | {models} models\")\n        \n        if collaboration_stats:\n            print(f\"\\nğŸ”— MULTI-MODEL COLLABORATION:\")\n            for collab_data in collaboration_stats:\n                num_models, count, conf = collab_data\n                num_models = num_models or 1\n                print(f\"   {num_models} model(s): {count:,} entities (avg conf: {conf:.3f})\")\n                \n    except Exception as e:\n        print(f\"   âŒ Could not retrieve analytics: {e}\")\n    \n    # Pipeline statistics\n    pipeline_stats = entity_pipeline.get_pipeline_statistics()\n    \n    print(f\"\\nğŸ”§ PIPELINE STATISTICS:\")\n    print(f\"   Documents Processed: {pipeline_stats['pipeline_stats']['documents_processed']:,}\")\n    print(f\"   Total Entities Found: {pipeline_stats['pipeline_stats']['total_entities_extracted']:,}\")\n    print(f\"   Processing Time: {pipeline_stats['pipeline_stats']['processing_time_total']:.2f}s\")\n    print(f\"   Device: {pipeline_stats['device']}\")\n    print(f\"   Loaded Models: {', '.join(pipeline_stats['loaded_models'])}\")\n    print(f\"   Supported Sources: {', '.join(pipeline_stats['supported_data_sources'])}\")\n    \n    # Individual model statistics\n    print(f\"\\nğŸ“Š INDIVIDUAL MODEL PERFORMANCE:\")\n    for model_name, stats in pipeline_stats['model_stats'].items():\n        if stats['texts_processed'] > 0:\n            entities_per_text = stats['entities_found'] / stats['texts_processed']\n            avg_time = stats['processing_time'] / stats['texts_processed']\n            print(f\"   {model_name:>12}: {stats['texts_processed']:>4} texts | {stats['entities_found']:>5} entities | {entities_per_text:>4.1f} avg/text | {avg_time:>4.2f}s avg\")\n    \n    # Storage statistics\n    storage_stats = pipeline_storage.storage_stats\n    if storage_stats['total_entities_stored'] > 0:\n        print(f\"\\nğŸ’¾ STORAGE STATISTICS:\")\n        print(f\"   Entities Stored: {storage_stats['total_entities_stored']:,}\")\n        print(f\"   Filings Processed: {storage_stats['filings_processed']:,}\")\n        print(f\"   Merged Entities: {storage_stats['merged_entities']:,}\")\n        print(f\"   Single-Model Entities: {storage_stats['single_model_entities']:,}\")\n        print(f\"   Failed Inserts: {storage_stats['failed_inserts']:,}\")\n        \n        merge_rate = (storage_stats['merged_entities'] / storage_stats['total_entities_stored'] * 100) if storage_stats['total_entities_stored'] > 0 else 0\n        print(f\"   Multi-Model Detection Rate: {merge_rate:.1f}%\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"âœ… EntityExtractionPipeline Analytics Complete!\")\n    print(\"=\"*80)\n\ndef run_production_batch(batch_size: int = 5, max_filings: int = 20) -> Dict:\n    \"\"\"Run production-ready batch processing with comprehensive monitoring\"\"\"\n    \n    print(f\"ğŸš€ PRODUCTION BATCH PROCESSING\")\n    print(f\"   ğŸ“¦ Batch size: {batch_size}\")\n    print(f\"   ğŸ“Š Max filings: {max_filings}\")\n    print(f\"   ğŸ–¥ï¸ Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n    print(f\"   ğŸ¤– Active models: {len(entity_pipeline.loaded_models)}\")\n    \n    production_start = time.time()\n    \n    # Get filings to process\n    all_filings = get_unprocessed_filings(limit=max_filings)\n    \n    if not all_filings:\n        return {\n            'success': False,\n            'message': 'No unprocessed filings found',\n            'recommendation': 'All SEC filings may already be processed'\n        }\n    \n    print(f\"   ğŸ“„ Found {len(all_filings)} unprocessed filings\")\n    \n    # Initialize production tracking\n    production_results = {\n        'batch_config': {\n            'batch_size': batch_size,\n            'max_filings': max_filings,\n            'total_filings_found': len(all_filings)\n        },\n        'processing_results': {\n            'successful_filings': 0,\n            'failed_filings': 0,\n            'total_entities_extracted': 0,\n            'total_sections_processed': 0,\n            'processing_errors': []\n        },\n        'model_performance': {},\n        'category_breakdown': {},\n        'timing': {\n            'start_time': datetime.now(),\n            'batch_times': [],\n            'avg_time_per_filing': 0\n        },\n        'quality_metrics': {\n            'avg_confidence_score': 0,\n            'multi_model_detection_rate': 0,\n            'entities_per_filing': 0\n        }\n    }\n    \n    # Process in batches\n    total_batches = (len(all_filings) + batch_size - 1) // batch_size\n    \n    for batch_num in range(total_batches):\n        batch_start_idx = batch_num * batch_size\n        batch_end_idx = min(batch_start_idx + batch_size, len(all_filings))\n        batch_filings = all_filings[batch_start_idx:batch_end_idx]\n        \n        print(f\"\\nğŸ“¦ Processing batch {batch_num + 1}/{total_batches} ({len(batch_filings)} filings)\")\n        \n        batch_start_time = time.time()\n        batch_entities = 0\n        batch_sections = 0\n        \n        for i, filing in enumerate(batch_filings, 1):\n            filing_start_time = time.time()\n            \n            print(f\"   ğŸ“„ [{batch_start_idx + i}/{len(all_filings)}] {filing['filing_type']} - {filing['company_domain']}\")\n            \n            try:\n                result = process_filing_with_pipeline(filing)\n                \n                if result['success']:\n                    production_results['processing_results']['successful_filings'] += 1\n                    batch_entities += result.get('entities_extracted', 0)\n                    batch_sections += result.get('sections_processed', 0)\n                    \n                    print(f\"      âœ… {result['entities_extracted']} entities, {result['sections_processed']} sections ({result['processing_time']}s)\")\n                    \n                    # Track model performance\n                    for entity in result.get('sample_entities', []):\n                        model = entity.get('primary_model', 'unknown')\n                        if model not in production_results['model_performance']:\n                            production_results['model_performance'][model] = 0\n                        production_results['model_performance'][model] += 1\n                        \n                        # Track categories\n                        category = entity.get('entity_type', 'unknown')\n                        if category not in production_results['category_breakdown']:\n                            production_results['category_breakdown'][category] = 0\n                        production_results['category_breakdown'][category] += 1\n                    \n                else:\n                    production_results['processing_results']['failed_filings'] += 1\n                    error_info = {\n                        'filing_id': result.get('filing_id'),\n                        'company': filing.get('company_domain'),\n                        'error': result.get('error', 'Unknown error'),\n                        'filing_type': filing.get('filing_type')\n                    }\n                    production_results['processing_results']['processing_errors'].append(error_info)\n                    print(f\"      âŒ Failed: {result.get('error', 'Unknown error')}\")\n                \n            except Exception as e:\n                production_results['processing_results']['failed_filings'] += 1\n                error_info = {\n                    'filing_id': filing.get('id'),\n                    'company': filing.get('company_domain'),\n                    'error': str(e),\n                    'filing_type': filing.get('filing_type')\n                }\n                production_results['processing_results']['processing_errors'].append(error_info)\n                print(f\"      âŒ Exception: {e}\")\n        \n        batch_time = time.time() - batch_start_time\n        production_results['timing']['batch_times'].append(batch_time)\n        \n        # Update totals\n        production_results['processing_results']['total_entities_extracted'] += batch_entities\n        production_results['processing_results']['total_sections_processed'] += batch_sections\n        \n        print(f\"   ğŸ“Š Batch {batch_num + 1} complete: {batch_entities} entities, {batch_sections} sections ({batch_time:.1f}s)\")\n        \n        # Brief pause between batches\n        if batch_num < total_batches - 1:\n            time.sleep(2)\n    \n    # Finalize results\n    production_time = time.time() - production_start\n    production_results['timing']['end_time'] = datetime.now()\n    production_results['timing']['total_processing_time'] = production_time\n    \n    successful = production_results['processing_results']['successful_filings']\n    if successful > 0:\n        production_results['timing']['avg_time_per_filing'] = production_time / successful\n        production_results['quality_metrics']['entities_per_filing'] = production_results['processing_results']['total_entities_extracted'] / successful\n    \n    # Success determination\n    success_rate = successful / len(all_filings) if len(all_filings) > 0 else 0\n    production_results['success'] = success_rate >= 0.8  # 80% success rate threshold\n    production_results['success_rate'] = success_rate\n    \n    return production_results\n\ndef display_production_summary(results: Dict) -> None:\n    \"\"\"Display comprehensive production batch summary\"\"\"\n    print(f\"\\n\" + \"=\"*80)\n    print(f\"ğŸ¯ PRODUCTION BATCH SUMMARY\")\n    print(f\"=\"*80)\n    \n    if not results.get('success', False):\n        print(f\"âŒ BATCH FAILED (Success rate: {results.get('success_rate', 0)*100:.1f}%)\")\n    else:\n        print(f\"âœ… BATCH SUCCESSFUL (Success rate: {results.get('success_rate', 0)*100:.1f}%)\")\n    \n    # Configuration and results\n    config = results.get('batch_config', {})\n    processing = results.get('processing_results', {})\n    timing = results.get('timing', {})\n    quality = results.get('quality_metrics', {})\n    \n    print(f\"\\nğŸ“Š PROCESSING RESULTS:\")\n    print(f\"   Total Filings Found: {config.get('total_filings_found', 0)}\")\n    print(f\"   Successful Filings: {processing.get('successful_filings', 0)}\")\n    print(f\"   Failed Filings: {processing.get('failed_filings', 0)}\")\n    print(f\"   Total Entities Extracted: {processing.get('total_entities_extracted', 0):,}\")\n    print(f\"   Total Sections Processed: {processing.get('total_sections_processed', 0):,}\")\n    \n    print(f\"\\nâ±ï¸ TIMING ANALYSIS:\")\n    print(f\"   Total Processing Time: {timing.get('total_processing_time', 0):.1f}s\")\n    print(f\"   Average Time per Filing: {timing.get('avg_time_per_filing', 0):.2f}s\")\n    if timing.get('batch_times'):\n        batch_times = timing['batch_times']\n        print(f\"   Fastest Batch: {min(batch_times):.1f}s\")\n        print(f\"   Slowest Batch: {max(batch_times):.1f}s\")\n    \n    print(f\"\\nğŸ“ˆ QUALITY METRICS:\")\n    print(f\"   Entities per Filing: {quality.get('entities_per_filing', 0):.1f}\")\n    \n    # Model performance\n    model_perf = results.get('model_performance', {})\n    if model_perf:\n        print(f\"\\nğŸ¤– MODEL CONTRIBUTIONS:\")\n        total_contributions = sum(model_perf.values())\n        for model, count in sorted(model_perf.items(), key=lambda x: x[1], reverse=True):\n            pct = (count / total_contributions * 100) if total_contributions > 0 else 0\n            print(f\"   {model:>12}: {count:>5} entities ({pct:>4.1f}%)\")\n    \n    # Category breakdown\n    categories = results.get('category_breakdown', {})\n    if categories:\n        print(f\"\\nğŸ·ï¸ ENTITY CATEGORIES FOUND:\")\n        total_entities = sum(categories.values())\n        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:10]:\n            pct = (count / total_entities * 100) if total_entities > 0 else 0\n            print(f\"   {category:<20}: {count:>4} entities ({pct:>4.1f}%)\")\n    \n    # Error summary\n    errors = processing.get('processing_errors', [])\n    if errors:\n        print(f\"\\nâŒ PROCESSING ERRORS ({len(errors)}):\")\n        error_types = {}\n        for error in errors:\n            error_type = error.get('error', 'Unknown').split(':')[0]\n            error_types[error_type] = error_types.get(error_type, 0) + 1\n        \n        for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):\n            print(f\"   {error_type}: {count} occurrences\")\n    \n    print(f\"\\n\" + \"=\"*80)\n\ndef analyze_model_agreement(filing_ref: str = None, limit: int = 100) -> Dict:\n    \"\"\"Analyze agreement between different models on entity detection\"\"\"\n    try:\n        conn = psycopg2.connect(**NEON_CONFIG)\n        cursor = conn.cursor()\n        \n        base_query = \"\"\"\n            SELECT entity_text, models_detected, all_confidences, is_merged\n            FROM system_uno.sec_entities_raw\n            WHERE models_detected IS NOT NULL\n        \"\"\"\n        \n        params = []\n        if filing_ref:\n            base_query += \" AND sec_filing_ref = %s\"\n            params.append(filing_ref)\n        \n        base_query += f\" ORDER BY confidence_score DESC LIMIT {limit}\"\n        \n        cursor.execute(base_query, params)\n        results = cursor.fetchall()\n        cursor.close()\n        conn.close()\n        \n        analysis = {\n            'total_entities': len(results),\n            'agreement_stats': {},\n            'high_agreement_entities': [],\n            'disagreement_entities': []\n        }\n        \n        for entity_text, models, confidences_json, is_merged in results:\n            num_models = len(models) if models else 1\n            \n            if num_models not in analysis['agreement_stats']:\n                analysis['agreement_stats'][num_models] = 0\n            analysis['agreement_stats'][num_models] += 1\n            \n            # Parse confidences\n            try:\n                confidences = json.loads(confidences_json) if confidences_json else {}\n            except:\n                confidences = {}\n            \n            # High agreement: multiple models with similar confidence\n            if num_models > 1 and confidences:\n                conf_values = list(confidences.values())\n                if len(conf_values) > 1:\n                    import numpy as np\n                    conf_std = np.std(conf_values)\n                    if conf_std < 0.1:  # Low standard deviation = high agreement\n                        analysis['high_agreement_entities'].append({\n                            'entity': entity_text,\n                            'models': models,\n                            'confidences': confidences,\n                            'std_dev': conf_std\n                        })\n                    else:\n                        analysis['disagreement_entities'].append({\n                            'entity': entity_text,\n                            'models': models,\n                            'confidences': confidences,\n                            'std_dev': conf_std\n                        })\n        \n        return analysis\n        \n    except Exception as e:\n        print(f\"âŒ Model agreement analysis failed: {e}\")\n        return {}\n\n# Generate initial analytics report\ngenerate_pipeline_analytics_report()\n\nprint(f\"\\nğŸ¯ PRODUCTION COMMANDS:\")\nprint(f\"   â€¢ Small batch:  results = run_production_batch(batch_size=3, max_filings=10)\")\nprint(f\"   â€¢ Medium batch: results = run_production_batch(batch_size=5, max_filings=25)\")\nprint(f\"   â€¢ Large batch:  results = run_production_batch(batch_size=8, max_filings=50)\")\nprint(f\"   â€¢ Show results: display_production_summary(results)\")\nprint(f\"   â€¢ Analytics:    generate_pipeline_analytics_report()\")\nprint(f\"   â€¢ Model agreement: agreement = analyze_model_agreement(limit=50)\")\n\nprint(f\"\\nâœ… EntityExtractionPipeline Production Interface Ready!\")\nprint(f\"ğŸš€ Features: Comprehensive monitoring, error tracking, quality metrics\")\nprint(f\"ğŸ“Š Ready for large-scale biotech SEC entity extraction!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}